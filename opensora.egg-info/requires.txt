colossalai>=0.3.4
mmengine>=0.10.3
pandas>=2.0.3
timm==0.9.16
rotary_embedding_torch==0.5.3
ftfy>=6.2.0
diffusers==0.27.2
accelerate==0.29.2
av>=12.0.0
numpy<2.0.0
gradio>=4.26.0
spaces>=0.28.3
ipykernel>=6.29.4
ipywidgets>=8.1.2
wandb>=0.17.0
tensorboard>=2.14.0
pandarallel>=1.6.5
pyarrow>=16.1.0
pre-commit>=3.5.0
openai
torch==2.0.1

[data]
gdown>=5.2.0
ninja>=1.11.1.1
shortuuid>=1.0.13
markdown2[all]
scikit-learn>=1.4.2
einops-exts>=0.0.4
decord==0.6.0
ptvsd==4.3.2
imageio-ffmpeg>=0.4.9
ffmpeg-python==0.2.0
lingua-language-detector==2.0.2
imageio>=2.34.1
setuptools==68.2.2
clip@ git+https://github.com/openai/CLIP.git
mmcv==2.1.0
mmdet==3.1.0
mmocr==1.0.1
detectron2@ git+https://github.com/facebookresearch/detectron2.git@ff53992

[eval]
detectron2@ git+https://github.com/facebookresearch/detectron2.git@ff53992
imageio>=2.34.1
pyiqa==0.1.10
scikit-learn>=1.4.2
scikit-image>=0.20.0
lvis==0.5.3
boto3>=1.34.113
easydict>=1.9
fairscale>=0.4.13
decord==0.6.0
pytorchvideo==0.1.5
lpips==0.1.4

[full]
gdown>=5.2.0
ninja>=1.11.1.1
shortuuid>=1.0.13
markdown2[all]
scikit-learn>=1.4.2
einops-exts>=0.0.4
decord==0.6.0
ptvsd==4.3.2
imageio-ffmpeg>=0.4.9
ffmpeg-python==0.2.0
lingua-language-detector==2.0.2
imageio>=2.34.1
setuptools==68.2.2
clip@ git+https://github.com/openai/CLIP.git
mmcv==2.1.0
mmdet==3.1.0
mmocr==1.0.1
detectron2@ git+https://github.com/facebookresearch/detectron2.git@ff53992
pyiqa==0.1.10
scikit-image>=0.20.0
lvis==0.5.3
boto3>=1.34.113
easydict>=1.9
fairscale>=0.4.13
pytorchvideo==0.1.5
lpips==0.1.4

[vae]
beartype==0.18.5
einops==0.8.0
einops-exts==0.0.4
opencv-python==4.9.0.80
pillow==10.3.0
